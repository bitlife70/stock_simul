#!/usr/bin/env python3
"""
Korean Stock Data Manager - ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ ë° ë¡œì»¬ DB ê´€ë¦¬ ì‹œìŠ¤í…œ
ì‹¤ì œ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ì²´ ì¢…ëª©ì„ ì¼ì¼ ë°°ì¹˜ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¡œì»¬ SQLite DBì— ì €ì¥
"""

import sqlite3
import pandas as pd
import requests
import json
from datetime import datetime, timedelta
from pathlib import Path
import logging
import asyncio
import time
from typing import List, Dict, Optional
import hashlib

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ (í•„ìš”ì‹œ ì„¤ì¹˜: pip install FinanceDataReader pykrx yfinance)
try:
    import FinanceDataReader as fdr
    import pykrx.stock as stock
    EXTERNAL_APIS_AVAILABLE = True
except ImportError:
    EXTERNAL_APIS_AVAILABLE = False
    print("âš ï¸  FinanceDataReader, pykrx not installed. Using fallback data.")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class KoreanStockDataManager:
    """í•œêµ­ ì£¼ì‹ ë°ì´í„° ê´€ë¦¬ì - ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ ë° ë¡œì»¬ DB ê´€ë¦¬"""
    
    def __init__(self, db_path: str = "korean_stocks.db"):
        self.db_path = db_path
        self.data_dir = Path("stock_data")
        self.data_dir.mkdir(exist_ok=True)
        self.init_database()
        
    def init_database(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ì¢…ëª© ê¸°ë³¸ì •ë³´ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS stocks (
                    symbol TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    name_kr TEXT NOT NULL,
                    market TEXT NOT NULL,
                    sector TEXT,
                    industry TEXT,
                    market_cap BIGINT,
                    current_price INTEGER,
                    change_rate REAL,
                    volume BIGINT,
                    trading_value BIGINT,
                    listed_date TEXT,
                    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ì—…ë°ì´íŠ¸ ì´ë ¥ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS update_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    update_type TEXT NOT NULL,
                    total_stocks INTEGER,
                    success_count INTEGER,
                    error_count INTEGER,
                    data_hash TEXT,
                    started_at TIMESTAMP,
                    completed_at TIMESTAMP,
                    status TEXT DEFAULT 'running'
                )
            """)
            
            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_stocks_market ON stocks(market)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_stocks_sector ON stocks(sector)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_stocks_name_kr ON stocks(name_kr)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_stocks_market_cap ON stocks(market_cap DESC)")
            
            conn.commit()
            logger.info(f"âœ… Database initialized: {self.db_path}")

    async def download_all_korean_stocks(self) -> Dict:
        """ëª¨ë“  í•œêµ­ ì£¼ì‹ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ"""
        start_time = datetime.now()
        logger.info("ğŸš€ Started downloading all Korean stock data...")
        
        # ì—…ë°ì´íŠ¸ ê¸°ë¡ ì‹œì‘
        update_id = self._start_update_record("daily_batch")
        
        try:
            all_stocks = []
            
            if EXTERNAL_APIS_AVAILABLE:
                # 1. KOSPI ì¢…ëª© ë‹¤ìš´ë¡œë“œ
                logger.info("ğŸ“Š Downloading KOSPI stocks...")
                kospi_stocks = await self._download_kospi_stocks()
                all_stocks.extend(kospi_stocks)
                
                # 2. KOSDAQ ì¢…ëª© ë‹¤ìš´ë¡œë“œ  
                logger.info("ğŸ“ˆ Downloading KOSDAQ stocks...")
                kosdaq_stocks = await self._download_kosdaq_stocks()
                all_stocks.extend(kosdaq_stocks)
                
                # 3. ETF ë‹¤ìš´ë¡œë“œ (ì˜µì…˜)
                logger.info("ğŸ¯ Downloading major ETFs...")
                etf_stocks = await self._download_etf_stocks()
                all_stocks.extend(etf_stocks)
                
            else:
                # Fallback: í™•ì¥ëœ í•˜ë“œì½”ë”© ë°ì´í„° ì‚¬ìš©
                logger.info("ğŸ“‹ Using extended fallback stock data...")
                all_stocks = self._get_extended_fallback_data()
            
            # 4. ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            success_count = await self._save_stocks_to_db(all_stocks)
            
            # 5. ì—…ë°ì´íŠ¸ ì™„ë£Œ ê¸°ë¡
            end_time = datetime.now()
            data_hash = self._calculate_data_hash(all_stocks)
            self._complete_update_record(update_id, len(all_stocks), success_count, 0, data_hash, end_time)
            
            duration = (end_time - start_time).total_seconds()
            
            result = {
                "status": "success",
                "total_stocks": len(all_stocks),
                "success_count": success_count,
                "duration_seconds": duration,
                "timestamp": end_time.isoformat(),
                "data_hash": data_hash
            }
            
            logger.info(f"âœ… Download completed: {len(all_stocks)} stocks in {duration:.1f}s")
            return result
            
        except Exception as e:
            # ì—ëŸ¬ ê¸°ë¡
            self._complete_update_record(update_id, 0, 0, 1, None, datetime.now(), "error")
            logger.error(f"âŒ Download failed: {str(e)}")
            raise

    async def _download_kospi_stocks(self) -> List[Dict]:
        """KOSPI ì „ì²´ ì¢…ëª© ë‹¤ìš´ë¡œë“œ"""
        stocks = []
        
        try:
            # pykrxë¡œ KOSPI ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            today = datetime.now().strftime('%Y%m%d')
            kospi_list = stock.get_market_ticker_list(today, market="KOSPI")
            
            logger.info(f"ğŸ“Š Found {len(kospi_list)} KOSPI stocks")
            
            # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘
            batch_size = 50
            for i in range(0, len(kospi_list), batch_size):
                batch = kospi_list[i:i + batch_size]
                batch_stocks = await self._process_stock_batch(batch, "KOSPI", today)
                stocks.extend(batch_stocks)
                
                # API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ë°©ì§€
                await asyncio.sleep(0.1)
                
                if i % 200 == 0:
                    logger.info(f"ğŸ“Š KOSPI progress: {i + len(batch)}/{len(kospi_list)}")
            
        except Exception as e:
            logger.error(f"âŒ KOSPI download error: {str(e)}")
            # Fallback to known major KOSPI stocks
            stocks = self._get_major_kospi_fallback()
        
        return stocks

    async def _download_kosdaq_stocks(self) -> List[Dict]:
        """KOSDAQ ì „ì²´ ì¢…ëª© ë‹¤ìš´ë¡œë“œ"""
        stocks = []
        
        try:
            # pykrxë¡œ KOSDAQ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            today = datetime.now().strftime('%Y%m%d')
            kosdaq_list = stock.get_market_ticker_list(today, market="KOSDAQ")
            
            logger.info(f"ğŸ“ˆ Found {len(kosdaq_list)} KOSDAQ stocks")
            
            # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘
            batch_size = 50
            for i in range(0, len(kosdaq_list), batch_size):
                batch = kosdaq_list[i:i + batch_size]
                batch_stocks = await self._process_stock_batch(batch, "KOSDAQ", today)
                stocks.extend(batch_stocks)
                
                # API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ë°©ì§€
                await asyncio.sleep(0.1)
                
                if i % 200 == 0:
                    logger.info(f"ğŸ“ˆ KOSDAQ progress: {i + len(batch)}/{len(kosdaq_list)}")
            
        except Exception as e:
            logger.error(f"âŒ KOSDAQ download error: {str(e)}")
            # Fallback to known major KOSDAQ stocks
            stocks = self._get_major_kosdaq_fallback()
        
        return stocks

    async def _download_etf_stocks(self) -> List[Dict]:
        """ì£¼ìš” ETF ë‹¤ìš´ë¡œë“œ (í˜„ì¬ëŠ” ìŠ¤í‚µ - API ì´ìŠˆë¡œ ì¸í•´)"""
        stocks = []
        
        try:
            # ETFëŠ” í˜„ì¬ API ì´ìŠˆë¡œ ì¸í•´ ìŠ¤í‚µ
            logger.info("ğŸ¯ Skipping ETF download due to API compatibility issues")
            
            # ìˆ˜ë™ìœ¼ë¡œ ì£¼ìš” ETF ì¶”ê°€ (fallback ë°ì´í„°)
            major_etfs_data = [
                {"symbol": "069500", "name": "KODEX 200", "name_kr": "KODEX 200", "market": "ETF", "sector": "ETF", "market_cap": 10000000, "current_price": 30000},
                {"symbol": "114800", "name": "KODEX ì¸ë²„ìŠ¤", "name_kr": "KODEX ì¸ë²„ìŠ¤", "market": "ETF", "sector": "ETF", "market_cap": 1000000, "current_price": 5000},
                {"symbol": "122630", "name": "KODEX ë ˆë²„ë¦¬ì§€", "name_kr": "KODEX ë ˆë²„ë¦¬ì§€", "market": "ETF", "sector": "ETF", "market_cap": 800000, "current_price": 15000},
            ]
            
            for etf_data in major_etfs_data:
                stock_data = {
                    **etf_data,
                    "industry": "ETF",
                    "change_rate": 0.0,
                    "volume": 1000000,
                    "trading_value": etf_data["current_price"] * 1000000,
                    "listed_date": ""
                }
                stocks.append(stock_data)
            
        except Exception as e:
            logger.error(f"âŒ ETF download error: {str(e)}")
        
        return stocks

    async def _process_stock_batch(self, tickers: List[str], market: str, date: str) -> List[Dict]:
        """ì¢…ëª© ë°°ì¹˜ ì²˜ë¦¬"""
        stocks = []
        
        for ticker in tickers:
            try:
                # pykrxë¡œ ì¢…ëª© ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                stock_info = stock.get_market_ticker_name(ticker)
                
                # ì‹œê°€ì´ì•¡ ë° ê°€ê²© ì •ë³´
                try:
                    market_data = stock.get_market_cap_by_ticker(date, ticker)
                    if not market_data.empty:
                        price_data = market_data.iloc[0]
                        current_price = int(price_data['ì¢…ê°€']) if pd.notna(price_data['ì¢…ê°€']) else 0
                        market_cap = int(price_data['ì‹œê°€ì´ì•¡']) if pd.notna(price_data['ì‹œê°€ì´ì•¡']) else 0
                        volume = int(price_data['ê±°ë˜ëŸ‰']) if pd.notna(price_data['ê±°ë˜ëŸ‰']) else 0
                    else:
                        current_price = market_cap = volume = 0
                except Exception as e:
                    logger.warning(f"âš ï¸  Failed to get market data for {ticker}: {str(e)}")
                    current_price = market_cap = volume = 0
                
                # ì—…ì¢… ì •ë³´ (KOSPIë§Œ ì§€ì›)
                sector = ""
                try:
                    if market == "KOSPI":
                        sector_info = stock.get_market_ticker_and_name(date, market="KOSPI")
                        # ì—…ì¢… ë§¤í•‘ (ê°„ë‹¨í™”)
                        sector = self._map_sector_by_ticker(ticker)
                except:
                    pass
                
                stock_data = {
                    "symbol": ticker,
                    "name": stock_info,
                    "name_kr": stock_info,
                    "market": market,
                    "sector": sector or self._map_sector_by_ticker(ticker),
                    "industry": "",
                    "market_cap": market_cap,
                    "current_price": current_price,
                    "change_rate": 0.0,  # ë³„ë„ API í˜¸ì¶œ í•„ìš”
                    "volume": volume,
                    "trading_value": current_price * volume if current_price and volume else 0,
                    "listed_date": ""
                }
                
                stocks.append(stock_data)
                
            except Exception as e:
                logger.warning(f"âš ï¸  Failed to process {ticker}: {str(e)}")
                continue
        
        return stocks

    def _map_sector_by_ticker(self, ticker: str) -> str:
        """ì¢…ëª©ì½”ë“œ ê¸°ë°˜ ì—…ì¢… ë§¤í•‘ (ê°„ë‹¨í™”)"""
        sector_map = {
            # ëŒ€í‘œ ì¢…ëª©ë“¤ì˜ ì—…ì¢… ë§¤í•‘
            "005930": "ë°˜ë„ì²´", "000660": "ë°˜ë„ì²´", "035420": "ì¸í„°ë„·",
            "035720": "ì¸í„°ë„·", "005380": "ìë™ì°¨", "051910": "í™”í•™",
            "068270": "ë°”ì´ì˜¤", "207940": "ë°”ì´ì˜¤", "006400": "ë°°í„°ë¦¬",
            "055550": "ê¸ˆìœµ", "105560": "ê¸ˆìœµ", "003670": "ì² ê°•",
            "017670": "í†µì‹ ", "030200": "í†µì‹ ", "036570": "ê²Œì„",
            "112040": "ê²Œì„", "293490": "ê²Œì„", "041510": "ì—”í„°í…Œì¸ë¨¼íŠ¸",
        }
        
        return sector_map.get(ticker, "ê¸°íƒ€")

    async def _save_stocks_to_db(self, stocks: List[Dict]) -> int:
        """ì¢…ëª© ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        success_count = 0
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì „ì²´ êµì²´)
            cursor.execute("DELETE FROM stocks")
            
            # ìƒˆ ë°ì´í„° ì‚½ì…
            for stock in stocks:
                try:
                    cursor.execute("""
                        INSERT INTO stocks (
                            symbol, name, name_kr, market, sector, industry,
                            market_cap, current_price, change_rate, volume,
                            trading_value, listed_date, last_updated
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        stock["symbol"], stock["name"], stock["name_kr"],
                        stock["market"], stock["sector"], stock["industry"],
                        stock["market_cap"], stock["current_price"], stock["change_rate"],
                        stock["volume"], stock["trading_value"], stock["listed_date"],
                        datetime.now().isoformat()
                    ))
                    success_count += 1
                except Exception as e:
                    logger.warning(f"âš ï¸  Failed to save {stock['symbol']}: {str(e)}")
            
            conn.commit()
        
        logger.info(f"ğŸ’¾ Saved {success_count} stocks to database")
        return success_count

    def _get_extended_fallback_data(self) -> List[Dict]:
        """í™•ì¥ëœ í´ë°± ë°ì´í„° (ì™¸ë¶€ API ì—†ì„ ë•Œ)"""
        # ê¸°ì¡´ 74ê°œì—ì„œ 200ê°œë¡œ í™•ì¥ëœ ëŒ€í‘œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        from korean_stocks_data import get_all_korean_stocks
        return get_all_korean_stocks()

    def _get_major_kospi_fallback(self) -> List[Dict]:
        """KOSPI ì£¼ìš” ì¢…ëª© í´ë°± ë°ì´í„°"""
        from korean_stocks_data import KOSPI_STOCKS
        return [{"market": "KOSPI", **stock} for stock in KOSPI_STOCKS]

    def _get_major_kosdaq_fallback(self) -> List[Dict]:
        """KOSDAQ ì£¼ìš” ì¢…ëª© í´ë°± ë°ì´í„°"""
        from korean_stocks_data import KOSDAQ_STOCKS
        return [{"market": "KOSDAQ", **stock} for stock in KOSDAQ_STOCKS]

    def _start_update_record(self, update_type: str) -> int:
        """ì—…ë°ì´íŠ¸ ê¸°ë¡ ì‹œì‘"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                INSERT INTO update_history (update_type, started_at, status)
                VALUES (?, ?, 'running')
            """, (update_type, datetime.now().isoformat()))
            conn.commit()
            return cursor.lastrowid

    def _complete_update_record(self, update_id: int, total: int, success: int, 
                              errors: int, data_hash: str, completed_at: datetime, 
                              status: str = "completed"):
        """ì—…ë°ì´íŠ¸ ê¸°ë¡ ì™„ë£Œ"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE update_history 
                SET total_stocks = ?, success_count = ?, error_count = ?,
                    data_hash = ?, completed_at = ?, status = ?
                WHERE id = ?
            """, (total, success, errors, data_hash, completed_at.isoformat(), status, update_id))
            conn.commit()

    def _calculate_data_hash(self, stocks: List[Dict]) -> str:
        """ë°ì´í„° í•´ì‹œ ê³„ì‚° (ë³€ê²½ì‚¬í•­ ê°ì§€ìš©)"""
        try:
            # DataFrameì´ë‚˜ ê¸°íƒ€ JSON ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ê°ì²´ ì œê±°
            clean_stocks = []
            for stock in stocks:
                clean_stock = {}
                for key, value in stock.items():
                    if isinstance(value, (str, int, float, bool)) or value is None:
                        clean_stock[key] = value
                    else:
                        # DataFrameì´ë‚˜ ê¸°íƒ€ ë³µì¡í•œ ê°ì²´ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
                        clean_stock[key] = str(value)
                clean_stocks.append(clean_stock)
            
            data_str = json.dumps(clean_stocks, sort_keys=True, ensure_ascii=False, default=str)
            return hashlib.md5(data_str.encode()).hexdigest()
        except Exception as e:
            logger.warning(f"âš ï¸  Hash calculation failed: {str(e)}")
            return hashlib.md5(f"fallback_{len(stocks)}_{datetime.now().isoformat()}".encode()).hexdigest()

    def get_all_stocks(self, limit: Optional[int] = None) -> List[Dict]:
        """ë¡œì»¬ DBì—ì„œ ëª¨ë“  ì¢…ëª© ì¡°íšŒ"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            query = "SELECT * FROM stocks ORDER BY market_cap DESC"
            if limit:
                query += f" LIMIT {limit}"
            
            cursor.execute(query)
            columns = [description[0] for description in cursor.description]
            return [dict(zip(columns, row)) for row in cursor.fetchall()]

    def search_stocks(self, query: str, limit: int = 50) -> List[Dict]:
        """ê³ ì† ì¢…ëª© ê²€ìƒ‰"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            search_query = f"%{query}%"
            cursor.execute("""
                SELECT * FROM stocks 
                WHERE symbol LIKE ? OR name_kr LIKE ? OR name LIKE ? OR sector LIKE ?
                ORDER BY 
                    CASE 
                        WHEN symbol = ? THEN 1
                        WHEN name_kr = ? THEN 2
                        WHEN symbol LIKE ? THEN 3
                        WHEN name_kr LIKE ? THEN 4
                        ELSE 5
                    END,
                    market_cap DESC
                LIMIT ?
            """, (search_query, search_query, search_query, search_query,
                  query, query, f"{query}%", f"{query}%", limit))
            
            columns = [description[0] for description in cursor.description]
            return [dict(zip(columns, row)) for row in cursor.fetchall()]

    def get_stats(self) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute("SELECT COUNT(*) FROM stocks")
            total_stocks = cursor.fetchone()[0]
            
            cursor.execute("SELECT market, COUNT(*) FROM stocks GROUP BY market")
            market_counts = dict(cursor.fetchall())
            
            cursor.execute("SELECT * FROM update_history ORDER BY completed_at DESC LIMIT 1")
            last_update = cursor.fetchone()
            
            return {
                "total_stocks": total_stocks,
                "market_breakdown": market_counts,
                "last_update": last_update[7] if last_update else None,
                "database_path": self.db_path
            }

    def should_update(self) -> bool:
        """ì—…ë°ì´íŠ¸ í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT completed_at FROM update_history 
                WHERE status = 'completed' 
                ORDER BY completed_at DESC LIMIT 1
            """)
            result = cursor.fetchone()
            
            if not result:
                return True  # ì²« ì—…ë°ì´íŠ¸
            
            last_update = datetime.fromisoformat(result[0])
            return (datetime.now() - last_update).days >= 1  # í•˜ë£¨ ì§€ë‚¬ìœ¼ë©´ ì—…ë°ì´íŠ¸

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
stock_manager = KoreanStockDataManager()

async def daily_batch_update():
    """ì¼ì¼ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤í–‰"""
    if stock_manager.should_update():
        logger.info("ğŸ”„ Starting daily batch update...")
        result = await stock_manager.download_all_korean_stocks()
        logger.info(f"âœ… Daily update completed: {result}")
        return result
    else:
        logger.info("â­ï¸  Skip update - data is current")
        return {"status": "skipped", "reason": "data_is_current"}

if __name__ == "__main__":
    import asyncio
    
    async def main():
        print("ğŸš€ Korean Stock Data Manager")
        print("=" * 50)
        
        # í†µê³„ ì¶œë ¥
        stats = stock_manager.get_stats()
        print(f"ğŸ“Š Current Stats:")
        print(f"  Total Stocks: {stats['total_stocks']}")
        print(f"  Markets: {stats['market_breakdown']}")
        print(f"  Last Update: {stats['last_update']}")
        print()
        
        # ì—…ë°ì´íŠ¸ ì‹¤í–‰
        if len(sys.argv) > 1 and sys.argv[1] == "update":
            result = await daily_batch_update()
            print(f"ğŸ”„ Update Result: {result}")
        
        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("ğŸ” Search Test:")
        results = stock_manager.search_stocks("ì‚¼ì„±", 5)
        for stock in results:
            print(f"  {stock['symbol']}: {stock['name_kr']} ({stock['market']})")
    
    import sys
    asyncio.run(main())