#!/usr/bin/env python3
"""
Korean Stock Data Manager - ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ ë° ë¡œì»¬ DB ê´€ë¦¬ ì‹œìŠ¤í…œ
ì‹¤ì œ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ì²´ ì¢…ëª©ì„ ì¼ì¼ ë°°ì¹˜ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¡œì»¬ SQLite DBì— ì €ì¥
"""

import sqlite3
import pandas as pd
import requests
import json
from datetime import datetime, timedelta
from pathlib import Path
import logging
import asyncio
import time
from typing import List, Dict, Optional
import hashlib

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ (í•„ìš”ì‹œ ì„¤ì¹˜: pip install FinanceDataReader pykrx yfinance)
try:
    import FinanceDataReader as fdr
    import pykrx.stock as stock
    EXTERNAL_APIS_AVAILABLE = True
except ImportError:
    EXTERNAL_APIS_AVAILABLE = False
    print("âš ï¸  FinanceDataReader, pykrx not installed. Using fallback data.")

# ì£¼ê°€ ë°ì´í„° ìºì‹œ
from functools import lru_cache
from typing import Union

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class KoreanStockDataManager:
    """í•œêµ­ ì£¼ì‹ ë°ì´í„° ê´€ë¦¬ì - ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ ë° ë¡œì»¬ DB ê´€ë¦¬"""
    
    def __init__(self, db_path: str = "korean_stocks.db"):
        self.db_path = db_path
        self.data_dir = Path("stock_data")
        self.data_dir.mkdir(exist_ok=True)
        self.init_database()
        
    def init_database(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ì¢…ëª© ê¸°ë³¸ì •ë³´ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS stocks (
                    symbol TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    name_kr TEXT NOT NULL,
                    market TEXT NOT NULL,
                    sector TEXT,
                    industry TEXT,
                    market_cap BIGINT,
                    current_price INTEGER,
                    change_rate REAL,
                    volume BIGINT,
                    trading_value BIGINT,
                    listed_date TEXT,
                    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ì—…ë°ì´íŠ¸ ì´ë ¥ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS update_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    update_type TEXT NOT NULL,
                    total_stocks INTEGER,
                    success_count INTEGER,
                    error_count INTEGER,
                    data_hash TEXT,
                    started_at TIMESTAMP,
                    completed_at TIMESTAMP,
                    status TEXT DEFAULT 'running'
                )
            """)
            
            # ì£¼ê°€ ë°ì´í„° í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS stock_prices (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    date TEXT NOT NULL,
                    open REAL,
                    high REAL,
                    low REAL,
                    close REAL,
                    volume INTEGER,
                    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(symbol, date)
                )
            """)
            
            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_stocks_market ON stocks(market)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_stocks_sector ON stocks(sector)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_stocks_name_kr ON stocks(name_kr)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_stocks_market_cap ON stocks(market_cap DESC)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_stock_prices_symbol ON stock_prices(symbol)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_stock_prices_date ON stock_prices(date)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_stock_prices_symbol_date ON stock_prices(symbol, date)")
            
            conn.commit()
            logger.info(f"âœ… Database initialized: {self.db_path}")

    async def download_all_korean_stocks(self) -> Dict:
        """ëª¨ë“  í•œêµ­ ì£¼ì‹ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ"""
        start_time = datetime.now()
        logger.info("ğŸš€ Started downloading all Korean stock data...")
        
        # ì—…ë°ì´íŠ¸ ê¸°ë¡ ì‹œì‘
        update_id = self._start_update_record("daily_batch")
        
        try:
            all_stocks = []
            
            if EXTERNAL_APIS_AVAILABLE:
                # 1. KOSPI ì¢…ëª© ë‹¤ìš´ë¡œë“œ
                logger.info("ğŸ“Š Downloading KOSPI stocks...")
                kospi_stocks = await self._download_kospi_stocks()
                all_stocks.extend(kospi_stocks)
                
                # 2. KOSDAQ ì¢…ëª© ë‹¤ìš´ë¡œë“œ  
                logger.info("ğŸ“ˆ Downloading KOSDAQ stocks...")
                kosdaq_stocks = await self._download_kosdaq_stocks()
                all_stocks.extend(kosdaq_stocks)
                
                # 3. ETF ë‹¤ìš´ë¡œë“œ (ì˜µì…˜)
                logger.info("ğŸ¯ Downloading major ETFs...")
                etf_stocks = await self._download_etf_stocks()
                all_stocks.extend(etf_stocks)
                
            else:
                # Fallback: í™•ì¥ëœ í•˜ë“œì½”ë”© ë°ì´í„° ì‚¬ìš©
                logger.info("ğŸ“‹ Using extended fallback stock data...")
                all_stocks = self._get_extended_fallback_data()
            
            # 4. ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            success_count = await self._save_stocks_to_db(all_stocks)
            
            # 5. ì—…ë°ì´íŠ¸ ì™„ë£Œ ê¸°ë¡
            end_time = datetime.now()
            data_hash = self._calculate_data_hash(all_stocks)
            self._complete_update_record(update_id, len(all_stocks), success_count, 0, data_hash, end_time)
            
            duration = (end_time - start_time).total_seconds()
            
            result = {
                "status": "success",
                "total_stocks": len(all_stocks),
                "success_count": success_count,
                "duration_seconds": duration,
                "timestamp": end_time.isoformat(),
                "data_hash": data_hash
            }
            
            logger.info(f"âœ… Download completed: {len(all_stocks)} stocks in {duration:.1f}s")
            return result
            
        except Exception as e:
            # ì—ëŸ¬ ê¸°ë¡
            self._complete_update_record(update_id, 0, 0, 1, None, datetime.now(), "error")
            logger.error(f"âŒ Download failed: {str(e)}")
            raise

    async def _download_kospi_stocks(self) -> List[Dict]:
        """KOSPI ì „ì²´ ì¢…ëª© ë‹¤ìš´ë¡œë“œ"""
        stocks = []
        
        try:
            # pykrxë¡œ KOSPI ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            today = datetime.now().strftime('%Y%m%d')
            kospi_list = stock.get_market_ticker_list(today, market="KOSPI")
            
            logger.info(f"ğŸ“Š Found {len(kospi_list)} KOSPI stocks")
            
            # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘
            batch_size = 50
            for i in range(0, len(kospi_list), batch_size):
                batch = kospi_list[i:i + batch_size]
                batch_stocks = await self._process_stock_batch(batch, "KOSPI", today)
                stocks.extend(batch_stocks)
                
                # API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ë°©ì§€
                await asyncio.sleep(0.1)
                
                if i % 200 == 0:
                    logger.info(f"ğŸ“Š KOSPI progress: {i + len(batch)}/{len(kospi_list)}")
            
        except Exception as e:
            logger.error(f"âŒ KOSPI download error: {str(e)}")
            # Fallback to known major KOSPI stocks
            stocks = self._get_major_kospi_fallback()
        
        return stocks

    async def _download_kosdaq_stocks(self) -> List[Dict]:
        """KOSDAQ ì „ì²´ ì¢…ëª© ë‹¤ìš´ë¡œë“œ"""
        stocks = []
        
        try:
            # pykrxë¡œ KOSDAQ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            today = datetime.now().strftime('%Y%m%d')
            kosdaq_list = stock.get_market_ticker_list(today, market="KOSDAQ")
            
            logger.info(f"ğŸ“ˆ Found {len(kosdaq_list)} KOSDAQ stocks")
            
            # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘
            batch_size = 50
            for i in range(0, len(kosdaq_list), batch_size):
                batch = kosdaq_list[i:i + batch_size]
                batch_stocks = await self._process_stock_batch(batch, "KOSDAQ", today)
                stocks.extend(batch_stocks)
                
                # API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ë°©ì§€
                await asyncio.sleep(0.1)
                
                if i % 200 == 0:
                    logger.info(f"ğŸ“ˆ KOSDAQ progress: {i + len(batch)}/{len(kosdaq_list)}")
            
        except Exception as e:
            logger.error(f"âŒ KOSDAQ download error: {str(e)}")
            # Fallback to known major KOSDAQ stocks
            stocks = self._get_major_kosdaq_fallback()
        
        return stocks

    async def _download_etf_stocks(self) -> List[Dict]:
        """ì£¼ìš” ETF ë‹¤ìš´ë¡œë“œ (í˜„ì¬ëŠ” ìŠ¤í‚µ - API ì´ìŠˆë¡œ ì¸í•´)"""
        stocks = []
        
        try:
            # ETFëŠ” í˜„ì¬ API ì´ìŠˆë¡œ ì¸í•´ ìŠ¤í‚µ
            logger.info("ğŸ¯ Skipping ETF download due to API compatibility issues")
            
            # ìˆ˜ë™ìœ¼ë¡œ ì£¼ìš” ETF ì¶”ê°€ (fallback ë°ì´í„°)
            major_etfs_data = [
                {"symbol": "069500", "name": "KODEX 200", "name_kr": "KODEX 200", "market": "ETF", "sector": "ETF", "market_cap": 10000000, "current_price": 30000},
                {"symbol": "114800", "name": "KODEX ì¸ë²„ìŠ¤", "name_kr": "KODEX ì¸ë²„ìŠ¤", "market": "ETF", "sector": "ETF", "market_cap": 1000000, "current_price": 5000},
                {"symbol": "122630", "name": "KODEX ë ˆë²„ë¦¬ì§€", "name_kr": "KODEX ë ˆë²„ë¦¬ì§€", "market": "ETF", "sector": "ETF", "market_cap": 800000, "current_price": 15000},
            ]
            
            for etf_data in major_etfs_data:
                stock_data = {
                    **etf_data,
                    "industry": "ETF",
                    "change_rate": 0.0,
                    "volume": 1000000,
                    "trading_value": etf_data["current_price"] * 1000000,
                    "listed_date": ""
                }
                stocks.append(stock_data)
            
        except Exception as e:
            logger.error(f"âŒ ETF download error: {str(e)}")
        
        return stocks

    async def _process_stock_batch(self, tickers: List[str], market: str, date: str) -> List[Dict]:
        """ì¢…ëª© ë°°ì¹˜ ì²˜ë¦¬"""
        stocks = []
        
        for ticker in tickers:
            try:
                # pykrxë¡œ ì¢…ëª© ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                stock_info = stock.get_market_ticker_name(ticker)
                
                # ì‹œê°€ì´ì•¡ ë° ê°€ê²© ì •ë³´
                try:
                    market_data = stock.get_market_cap_by_ticker(date, ticker)
                    if not market_data.empty:
                        price_data = market_data.iloc[0]
                        current_price = int(price_data['ì¢…ê°€']) if pd.notna(price_data['ì¢…ê°€']) else 0
                        market_cap = int(price_data['ì‹œê°€ì´ì•¡']) if pd.notna(price_data['ì‹œê°€ì´ì•¡']) else 0
                        volume = int(price_data['ê±°ë˜ëŸ‰']) if pd.notna(price_data['ê±°ë˜ëŸ‰']) else 0
                    else:
                        current_price = market_cap = volume = 0
                except Exception as e:
                    logger.warning(f"âš ï¸  Failed to get market data for {ticker}: {str(e)}")
                    current_price = market_cap = volume = 0
                
                # ì—…ì¢… ì •ë³´ (KOSPIë§Œ ì§€ì›)
                sector = ""
                try:
                    if market == "KOSPI":
                        sector_info = stock.get_market_ticker_and_name(date, market="KOSPI")
                        # ì—…ì¢… ë§¤í•‘ (ê°„ë‹¨í™”)
                        sector = self._map_sector_by_ticker(ticker)
                except:
                    pass
                
                stock_data = {
                    "symbol": ticker,
                    "name": stock_info,
                    "name_kr": stock_info,
                    "market": market,
                    "sector": sector or self._map_sector_by_ticker(ticker),
                    "industry": "",
                    "market_cap": market_cap,
                    "current_price": current_price,
                    "change_rate": 0.0,  # ë³„ë„ API í˜¸ì¶œ í•„ìš”
                    "volume": volume,
                    "trading_value": current_price * volume if current_price and volume else 0,
                    "listed_date": ""
                }
                
                stocks.append(stock_data)
                
            except Exception as e:
                logger.warning(f"âš ï¸  Failed to process {ticker}: {str(e)}")
                continue
        
        return stocks

    def _map_sector_by_ticker(self, ticker: str) -> str:
        """ì¢…ëª©ì½”ë“œ ê¸°ë°˜ ì—…ì¢… ë§¤í•‘ (ê°„ë‹¨í™”)"""
        sector_map = {
            # ëŒ€í‘œ ì¢…ëª©ë“¤ì˜ ì—…ì¢… ë§¤í•‘
            "005930": "ë°˜ë„ì²´", "000660": "ë°˜ë„ì²´", "035420": "ì¸í„°ë„·",
            "035720": "ì¸í„°ë„·", "005380": "ìë™ì°¨", "051910": "í™”í•™",
            "068270": "ë°”ì´ì˜¤", "207940": "ë°”ì´ì˜¤", "006400": "ë°°í„°ë¦¬",
            "055550": "ê¸ˆìœµ", "105560": "ê¸ˆìœµ", "003670": "ì² ê°•",
            "017670": "í†µì‹ ", "030200": "í†µì‹ ", "036570": "ê²Œì„",
            "112040": "ê²Œì„", "293490": "ê²Œì„", "041510": "ì—”í„°í…Œì¸ë¨¼íŠ¸",
        }
        
        return sector_map.get(ticker, "ê¸°íƒ€")

    async def _save_stocks_to_db(self, stocks: List[Dict]) -> int:
        """ì¢…ëª© ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        success_count = 0
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì „ì²´ êµì²´)
            cursor.execute("DELETE FROM stocks")
            
            # ìƒˆ ë°ì´í„° ì‚½ì…
            for stock in stocks:
                try:
                    cursor.execute("""
                        INSERT INTO stocks (
                            symbol, name, name_kr, market, sector, industry,
                            market_cap, current_price, change_rate, volume,
                            trading_value, listed_date, last_updated
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        stock["symbol"], stock["name"], stock["name_kr"],
                        stock["market"], stock["sector"], stock["industry"],
                        stock["market_cap"], stock["current_price"], stock["change_rate"],
                        stock["volume"], stock["trading_value"], stock["listed_date"],
                        datetime.now().isoformat()
                    ))
                    success_count += 1
                except Exception as e:
                    logger.warning(f"âš ï¸  Failed to save {stock['symbol']}: {str(e)}")
            
            conn.commit()
        
        logger.info(f"ğŸ’¾ Saved {success_count} stocks to database")
        return success_count

    def _get_extended_fallback_data(self) -> List[Dict]:
        """í™•ì¥ëœ í´ë°± ë°ì´í„° (ì™¸ë¶€ API ì—†ì„ ë•Œ)"""
        # ê¸°ì¡´ 74ê°œì—ì„œ 200ê°œë¡œ í™•ì¥ëœ ëŒ€í‘œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        from korean_stocks_data import get_all_korean_stocks
        return get_all_korean_stocks()

    def _get_major_kospi_fallback(self) -> List[Dict]:
        """KOSPI ì£¼ìš” ì¢…ëª© í´ë°± ë°ì´í„°"""
        from korean_stocks_data import KOSPI_STOCKS
        return [{"market": "KOSPI", **stock} for stock in KOSPI_STOCKS]

    def _get_major_kosdaq_fallback(self) -> List[Dict]:
        """KOSDAQ ì£¼ìš” ì¢…ëª© í´ë°± ë°ì´í„°"""
        from korean_stocks_data import KOSDAQ_STOCKS
        return [{"market": "KOSDAQ", **stock} for stock in KOSDAQ_STOCKS]

    def _start_update_record(self, update_type: str) -> int:
        """ì—…ë°ì´íŠ¸ ê¸°ë¡ ì‹œì‘"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                INSERT INTO update_history (update_type, started_at, status)
                VALUES (?, ?, 'running')
            """, (update_type, datetime.now().isoformat()))
            conn.commit()
            return cursor.lastrowid

    def _complete_update_record(self, update_id: int, total: int, success: int, 
                              errors: int, data_hash: str, completed_at: datetime, 
                              status: str = "completed"):
        """ì—…ë°ì´íŠ¸ ê¸°ë¡ ì™„ë£Œ"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE update_history 
                SET total_stocks = ?, success_count = ?, error_count = ?,
                    data_hash = ?, completed_at = ?, status = ?
                WHERE id = ?
            """, (total, success, errors, data_hash, completed_at.isoformat(), status, update_id))
            conn.commit()

    def _calculate_data_hash(self, stocks: List[Dict]) -> str:
        """ë°ì´í„° í•´ì‹œ ê³„ì‚° (ë³€ê²½ì‚¬í•­ ê°ì§€ìš©)"""
        try:
            # DataFrameì´ë‚˜ ê¸°íƒ€ JSON ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ê°ì²´ ì œê±°
            clean_stocks = []
            for stock in stocks:
                clean_stock = {}
                for key, value in stock.items():
                    if isinstance(value, (str, int, float, bool)) or value is None:
                        clean_stock[key] = value
                    else:
                        # DataFrameì´ë‚˜ ê¸°íƒ€ ë³µì¡í•œ ê°ì²´ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
                        clean_stock[key] = str(value)
                clean_stocks.append(clean_stock)
            
            data_str = json.dumps(clean_stocks, sort_keys=True, ensure_ascii=False, default=str)
            return hashlib.md5(data_str.encode()).hexdigest()
        except Exception as e:
            logger.warning(f"âš ï¸  Hash calculation failed: {str(e)}")
            return hashlib.md5(f"fallback_{len(stocks)}_{datetime.now().isoformat()}".encode()).hexdigest()

    def get_all_stocks(self, limit: Optional[int] = None) -> List[Dict]:
        """ë¡œì»¬ DBì—ì„œ ëª¨ë“  ì¢…ëª© ì¡°íšŒ"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            query = "SELECT * FROM stocks ORDER BY market_cap DESC"
            if limit:
                query += f" LIMIT {limit}"
            
            cursor.execute(query)
            columns = [description[0] for description in cursor.description]
            return [dict(zip(columns, row)) for row in cursor.fetchall()]

    def search_stocks(self, query: str, limit: int = 50) -> List[Dict]:
        """ê³ ì† ì¢…ëª© ê²€ìƒ‰"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            search_query = f"%{query}%"
            cursor.execute("""
                SELECT * FROM stocks 
                WHERE symbol LIKE ? OR name_kr LIKE ? OR name LIKE ? OR sector LIKE ?
                ORDER BY 
                    CASE 
                        WHEN symbol = ? THEN 1
                        WHEN name_kr = ? THEN 2
                        WHEN symbol LIKE ? THEN 3
                        WHEN name_kr LIKE ? THEN 4
                        ELSE 5
                    END,
                    market_cap DESC
                LIMIT ?
            """, (search_query, search_query, search_query, search_query,
                  query, query, f"{query}%", f"{query}%", limit))
            
            columns = [description[0] for description in cursor.description]
            return [dict(zip(columns, row)) for row in cursor.fetchall()]

    def get_stats(self) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute("SELECT COUNT(*) FROM stocks")
            total_stocks = cursor.fetchone()[0]
            
            cursor.execute("SELECT market, COUNT(*) FROM stocks GROUP BY market")
            market_counts = dict(cursor.fetchall())
            
            cursor.execute("SELECT * FROM update_history ORDER BY completed_at DESC LIMIT 1")
            last_update = cursor.fetchone()
            
            return {
                "total_stocks": total_stocks,
                "market_breakdown": market_counts,
                "last_update": last_update[7] if last_update else None,
                "database_path": self.db_path
            }

    def should_update(self) -> bool:
        """ì—…ë°ì´íŠ¸ í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT completed_at FROM update_history 
                WHERE status = 'completed' 
                ORDER BY completed_at DESC LIMIT 1
            """)
            result = cursor.fetchone()
            
            if not result:
                return True  # ì²« ì—…ë°ì´íŠ¸
            
            last_update = datetime.fromisoformat(result[0])
            return (datetime.now() - last_update).days >= 1  # í•˜ë£¨ ì§€ë‚¬ìœ¼ë©´ ì—…ë°ì´íŠ¸

    def get_stock_price_data(self, symbol: str, start_date: Optional[str] = None, 
                           end_date: Optional[str] = None, days: int = 365) -> List[Dict]:
        """ì¢…ëª©ì˜ ì£¼ê°€ ë°ì´í„° ì¡°íšŒ (OHLCV)"""
        try:
            # ë‚ ì§œ ë²”ìœ„ ì„¤ì •
            if not end_date:
                end_date = datetime.now().strftime('%Y-%m-%d')
            
            if not start_date:
                start_dt = datetime.strptime(end_date, '%Y-%m-%d') - timedelta(days=days)
                start_date = start_dt.strftime('%Y-%m-%d')
            
            # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
            cached_data = self._get_cached_price_data(symbol, start_date, end_date)
            if cached_data:
                logger.info(f"ğŸ“Š Using cached data for {symbol} ({len(cached_data)} records)")
                return cached_data
            
            # ì‹¤ì œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            if EXTERNAL_APIS_AVAILABLE:
                price_data = self._fetch_real_price_data(symbol, start_date, end_date)
                if price_data:
                    # ìºì‹œì— ì €ì¥
                    self._cache_price_data(symbol, price_data)
                    return price_data
            
            # í´ë°±: ê°€ìƒ ë°ì´í„° ìƒì„±
            logger.warning(f"âš ï¸  Using fallback data for {symbol}")
            return self._generate_fallback_price_data(symbol, start_date, end_date)
            
        except Exception as e:
            logger.error(f"âŒ Error getting price data for {symbol}: {str(e)}")
            return self._generate_fallback_price_data(symbol, start_date, end_date)

    def _get_cached_price_data(self, symbol: str, start_date: str, end_date: str) -> Optional[List[Dict]]:
        """ìºì‹œëœ ì£¼ê°€ ë°ì´í„° ì¡°íšŒ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT date, open, high, low, close, volume
                    FROM stock_prices 
                    WHERE symbol = ? AND date >= ? AND date <= ?
                    ORDER BY date ASC
                """, (symbol, start_date, end_date))
                
                rows = cursor.fetchall()
                if len(rows) > 5:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìºì‹œ ì‚¬ìš©
                    return [
                        {
                            "date": row[0],
                            "open": float(row[1]) if row[1] else 0,
                            "high": float(row[2]) if row[2] else 0,
                            "low": float(row[3]) if row[3] else 0,
                            "close": float(row[4]) if row[4] else 0,
                            "volume": int(row[5]) if row[5] else 0
                        }
                        for row in rows
                    ]
        except Exception as e:
            logger.warning(f"âš ï¸  Cache lookup failed for {symbol}: {str(e)}")
        
        return None

    def _fetch_real_price_data(self, symbol: str, start_date: str, end_date: str) -> Optional[List[Dict]]:
        """ì‹¤ì œ ì£¼ê°€ ë°ì´í„° ì¡°íšŒ (pykrx ë˜ëŠ” FinanceDataReader)"""
        try:
            # ë°©ë²• 1: pykrx ì‚¬ìš©
            try:
                start_fmt = start_date.replace('-', '')
                end_fmt = end_date.replace('-', '')
                
                df = stock.get_market_ohlcv_by_date(start_fmt, end_fmt, symbol)
                
                if not df.empty:
                    logger.info(f"ğŸ“ˆ Retrieved {len(df)} days of data for {symbol} via pykrx")
                    
                    price_data = []
                    for date_str, row in df.iterrows():
                        price_data.append({
                            "date": date_str.strftime('%Y-%m-%d'),
                            "open": float(row['ì‹œê°€']) if pd.notna(row['ì‹œê°€']) else 0,
                            "high": float(row['ê³ ê°€']) if pd.notna(row['ê³ ê°€']) else 0,
                            "low": float(row['ì €ê°€']) if pd.notna(row['ì €ê°€']) else 0,
                            "close": float(row['ì¢…ê°€']) if pd.notna(row['ì¢…ê°€']) else 0,
                            "volume": int(row['ê±°ë˜ëŸ‰']) if pd.notna(row['ê±°ë˜ëŸ‰']) else 0
                        })
                    
                    return price_data
            except Exception as e:
                logger.warning(f"âš ï¸  pykrx failed for {symbol}: {str(e)}")
            
            # ë°©ë²• 2: FinanceDataReader ì‚¬ìš©
            try:
                df = fdr.DataReader(symbol, start_date, end_date)
                
                if not df.empty:
                    logger.info(f"ğŸ“ˆ Retrieved {len(df)} days of data for {symbol} via FDR")
                    
                    price_data = []
                    for date_str, row in df.iterrows():
                        price_data.append({
                            "date": date_str.strftime('%Y-%m-%d'),
                            "open": float(row['Open']) if pd.notna(row['Open']) else 0,
                            "high": float(row['High']) if pd.notna(row['High']) else 0,
                            "low": float(row['Low']) if pd.notna(row['Low']) else 0,
                            "close": float(row['Close']) if pd.notna(row['Close']) else 0,
                            "volume": int(row['Volume']) if pd.notna(row['Volume']) else 0
                        })
                    
                    return price_data
            except Exception as e:
                logger.warning(f"âš ï¸  FinanceDataReader failed for {symbol}: {str(e)}")
            
        except Exception as e:
            logger.error(f"âŒ Real data fetch failed for {symbol}: {str(e)}")
        
        return None

    def _cache_price_data(self, symbol: str, price_data: List[Dict]):
        """ì£¼ê°€ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
                cursor.execute("DELETE FROM stock_prices WHERE symbol = ?", (symbol,))
                
                # ìƒˆ ë°ì´í„° ì‚½ì…
                for data in price_data:
                    cursor.execute("""
                        INSERT OR REPLACE INTO stock_prices 
                        (symbol, date, open, high, low, close, volume, last_updated)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        symbol, data['date'], data['open'], data['high'],
                        data['low'], data['close'], data['volume'],
                        datetime.now().isoformat()
                    ))
                
                conn.commit()
                logger.info(f"ğŸ’¾ Cached {len(price_data)} price records for {symbol}")
                
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to cache data for {symbol}: {str(e)}")

    def _generate_fallback_price_data(self, symbol: str, start_date: str, end_date: str) -> List[Dict]:
        """í´ë°±ìš© ê°€ìƒ ì£¼ê°€ ë°ì´í„° ìƒì„±"""
        import random
        
        # ì¢…ëª©ë³„ ê¸°ì¤€ ê°€ê²© ì„¤ì •
        base_prices = {
            "005930": 70000,  # ì‚¼ì„±ì „ì
            "000660": 120000,  # SKí•˜ì´ë‹‰ìŠ¤
            "035420": 200000,  # NAVER
            "035720": 50000,   # ì¹´ì¹´ì˜¤
            "005380": 180000,  # í˜„ëŒ€ì°¨
        }
        
        base_price = base_prices.get(symbol, 50000)
        
        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d')
        
        price_data = []
        current_date = start_dt
        current_price = base_price
        
        while current_date <= end_dt:
            # ì£¼ë§ ê±´ë„ˆë›°ê¸°
            if current_date.weekday() < 5:  # ì›”-ê¸ˆìš”ì¼ë§Œ
                # ì¼ì¼ ë³€ë™ë¥  (-3% ~ +3%)
                change_rate = random.uniform(-0.03, 0.03)
                new_price = current_price * (1 + change_rate)
                
                # OHLC ìƒì„±
                high = new_price * random.uniform(1.0, 1.02)
                low = new_price * random.uniform(0.98, 1.0)
                open_price = current_price * random.uniform(0.99, 1.01)
                close_price = new_price
                
                volume = random.randint(100000, 5000000)
                
                price_data.append({
                    "date": current_date.strftime('%Y-%m-%d'),
                    "open": round(open_price),
                    "high": round(high),
                    "low": round(low),
                    "close": round(close_price),
                    "volume": volume
                })
                
                current_price = new_price
            
            current_date += timedelta(days=1)
        
        logger.info(f"ğŸ² Generated {len(price_data)} fallback price records for {symbol}")
        return price_data

    def clear_price_cache(self, symbol: Optional[str] = None):
        """ì£¼ê°€ ë°ì´í„° ìºì‹œ ì‚­ì œ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                if symbol:
                    cursor.execute("DELETE FROM stock_prices WHERE symbol = ?", (symbol,))
                    logger.info(f"ğŸ—‘ï¸  Cleared price cache for {symbol}")
                else:
                    cursor.execute("DELETE FROM stock_prices")
                    logger.info("ğŸ—‘ï¸  Cleared all price cache")
                conn.commit()
        except Exception as e:
            logger.error(f"âŒ Failed to clear cache: {str(e)}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
stock_manager = KoreanStockDataManager()

async def daily_batch_update():
    """ì¼ì¼ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤í–‰"""
    if stock_manager.should_update():
        logger.info("ğŸ”„ Starting daily batch update...")
        result = await stock_manager.download_all_korean_stocks()
        logger.info(f"âœ… Daily update completed: {result}")
        return result
    else:
        logger.info("â­ï¸  Skip update - data is current")
        return {"status": "skipped", "reason": "data_is_current"}

if __name__ == "__main__":
    import asyncio
    
    async def main():
        print("ğŸš€ Korean Stock Data Manager")
        print("=" * 50)
        
        # í†µê³„ ì¶œë ¥
        stats = stock_manager.get_stats()
        print(f"ğŸ“Š Current Stats:")
        print(f"  Total Stocks: {stats['total_stocks']}")
        print(f"  Markets: {stats['market_breakdown']}")
        print(f"  Last Update: {stats['last_update']}")
        print()
        
        # ì—…ë°ì´íŠ¸ ì‹¤í–‰
        if len(sys.argv) > 1 and sys.argv[1] == "update":
            result = await daily_batch_update()
            print(f"ğŸ”„ Update Result: {result}")
        
        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("ğŸ” Search Test:")
        results = stock_manager.search_stocks("ì‚¼ì„±", 5)
        for stock in results:
            print(f"  {stock['symbol']}: {stock['name_kr']} ({stock['market']})")
    
    import sys
    asyncio.run(main())